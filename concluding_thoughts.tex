\chapter{Conclusions}

\section{Introduction} This is the final chapter of the thesis. It consists of two sections. The first section explores potential further study to the research that was presented in this thesis. There are three main avenues for further study. The first avenue is general next steps, improving the models that were used in this thesis in the way that they were used in this thesis. The second avenue explore a how PTMs can be applied in other ways rather than just calssifying passages of texts as done here. The final avenue explores how other text data types might be available to be analysed with PTMs. The second section of this chapter summarises the thesis and presents some concluding thoughts.

\section{Future Research} Research on the use of NLP models with police data is likely to expand considerably. The field of NLP is growing continuously, and NLP models are improving. The application of NLP to police data is and will continue to be dynamic. This section is split into three sub-sections. Firstly, there is a section on models. This section focuses broadly on potential improvements to the study that are beyond its present scope. The applications section is a brief description of the manner in which NLP models can be used more widely and the third explores additional data types.

\subsection{Models} This section focuses on the manner in which future research can improve the models that were presented here. The focus is on the use of PTMs to classify short texts.

\subsubsection{Further replication} The studies that were presented here are narrow in scope. Only one type of crime and three types of classification were examined. Although this was partially replicated across two different police forces, the study should be expanded to include additional crimes, different classifications, and other police forces. The replication of the use cases at different police forces would produce a much more refined understanding of their potential for reuse. If models can be reused across police forces, the labelling burden would decrease – only a single model, rather than 43 separate ones (one for each force in the UK), would need to be produced. 

\subsubsection{Type} This thesis is based on the BERT model. Other PTMs have been produced since BERT was first released, and they are available for free use. Each of these PTMs has distinct characteristics, capabilities, and focal linguistic areas. By experimenting with different kinds of PTMs, one can discover which one works best for a specific uses case. For example, ROBERTA \parencite{liu2019roberta}, a popular PTM, uses a different method to define the words that are used. It handles previously unseen words more robustly. Police data that contain numerous acronyms or obscure words may be represented more accurately by a model of this kind. Consequently, the classifications may become more accurate. Other models have larger architectures, that is, they enable more parameters to be tuned. Such models can represent more intricate nuances in texts and therefore yield more accurate classifications. Model types are likely to evolve. The identification of the models that are most suitable for police data is likely to be a continuous process.

\subsubsection{Hyperparameter tuning} Hyperparameters were introduced in an earlier part of the exposition. Hyperparameters are variables in model formulations that alter the training of the model slightly. An example of a hyperparameter is the number of epochs, that is, the number of instances on which the whole training set is used to train the model. Three epochs were used in this study – the model saw each piece of training data on three separate occasions. The tuning of hyperparameters involves adjusting their values in order to optimise performance. This tuning can be a time-consuming process, but it is important because an appropriate combination of hyperparameters can improve model performance. Hyperparameters were not tuned in the studies that were presented here because the thesis is driven by a desire to use simplified processes for text classification that can be implemented easily by a police force. The results from the thesis indicate that default, that is, untuned, hyperparameters produce satisfactory models. Hyperparameter tuning could lead to more accurate classifications or to lower requirements for labelled data. In any event, hyperparameter tuning produce an improvement in model performance and is thus a suitable avenue for further research.

\subsubsection{Outcome weighting} In this research, misclassifications and correct classifications were weighted equally. Therefore, the models were trained to reduce the number of incorrect classifications. However, as explored in the conclusion to Study 2, misclassification is not equally in all instances. For instance, missing a burglary in which a car is stolen may be less desirable than the misclassification of a burglary in which no car is stolen. More vividly, missing a vulnerable victim may be more costly than misclassifying a nonvulnerable victim.

A technique that is called \say{outcome weighting} is used in machine learning to adjust the importance of different outcomes in classification problems. For example, missing a vulnerable victim might be deemed to be twice as costly as classifying a nonvulnerable victim as vulnerable. This cost function must be built with the end user so that their understanding of the problem and the costs of misclassification can be coded into the training of the model. Typically, this weighting can be encoded into the loss function, changing the training of the model. Alternatively, the model outputs can be used in a more sophisticated way so as to deliver the desired outcome.



\subsubsection{Vocabulary} BERT recognises a set of words. This set is called a vocabulary. The benefit of a word being in the vocabulary is that it has a clearly defined numerical representation. If a word is not in the vocabulary, then it is broken down into word pieces until it is recognised. In extreme cases, some words can be classified as \say{unknown}. Breaking a word into pieces can destroy some of its meaning because it is not represented as a single entity. In texts with many out-of-vocabulary words, the meaning of those words may not be represented accurately. Consequently, the classification models may become less accurate.

There are two ways to overcome this problem. Firstly, the vocabulary of BERT can be extended. The most popular unknown words can be added to the vocabulary, thus preventing words form being broken down into pieces. Secondly, unknown words can be changed to words that are already within the BERT vocabulary. For instance, \say{untidy} was not recognised by BERT and can be replaced with \say{messy} or \say{not tidy}, which are both recognised by BERT.

Overall, making texts and BERT vocabularies more similar can help to improve the performance of PTMs on specific tasks by increasing the extent to which the models understand the domains in question.

\subsubsection{Pre-train} As mentioned previously, there are two stages to utilising a BERT model. There is the pretraining element, which is resource intensive and equips the model with a general understanding of language, and there is also the pretraining that is conducted for each specific task. Pretraining was not completed in the studies that are presented here, but scholars in other domains who have accessed sufficient data have completed it. When this pretraining is conducted, it is possible to build new variants of BERT. For instance, Legal-BERT was built to understand legal documents \parencite{legal_bert}. Another variation, which is trained on medical data, is called med-BERT \parencite{med_bert}.

Pretraining a BERT model on police data, perhaps exclusively MO data from several different forces, in order to produce an MO-BERT would be an interesting avenue for future research. Given the successes that have been achieved in other domains, this new model is likely to perform better at classifying MO texts than the regular BERT. This approach may save time and resources that would otherwise need to be allocated to fine-tuning for each additional task as it would possess a superior understanding of the domain-specific language from the outset.

This section demonstrated that there are a number of interesting avenues for additional research that would enhance the classification work that was described in this thesis. The next section takes this further by exploring other NLP techniques that are not intended for the classification of text passages and their potential for enhancing POP.

\subsection{Applications} This next section introduces additional applications of PTMs above the classification type that was used in this research. Additional applications are important because they allow information to be extratcted from the data in different ways or enable access to the key elements of the data (e.g. summarisation).

\subsubsection{Question and Answer} Question answering (Q\&A) is an NLP task that involves using a PTM to answer questions that are posed in natural language, given a text which contains the answer. For example, a police officer may obtain one or more documents. These documents are then submitted to the PTM along with a question. The PTM generates a response by only using the text of the documents. Q\&A systems can be designed to answer a wide range of questions, including factual questions, questions about definitions, and queries about individuals. However, they have not been trialled with crime documents, and their performance in this domain is unknown. This may be more useful when the incidence of a crime is low or when a specific response, rather than a binary classification, is needed.

\subsubsection{Named Entity Recognition} Named entity recognition (NER) is another NLP task that is based on classification. Instead of classifying a passage of text, it classifies every word within it. The typical task is to extract the names of organisations, people, and places from a passage. The PTM labels each word as either “nothing”, “a person”, “an organisation“, or “a place”. For example, in the sentence ”Boris Johnson was born in New York on 19 June 1964”, the named entities are “Boris Johnson”, “New York”, and “19 June 1964”. When words are identified positively, they can be extracted from the text. The PTM uses both the word and the context in which it appears to arrive at a classification. Therefore, names or places that do not feature in the training material can still be extracted correctly because they are used in similar contexts. In policing, the words of interest may not be people or places, but, for example, weapons that are used in assaults. 


\subsubsection{Summarisation} Text summarisation involves the production of short synopses from longer documents or collections of documents. The idea is to retain the most important information from the original documents so that the summarisation can be read in isolation. This task is well understood in the NLP field, but it is hard to generalise across different language domains because 1) it is inherently difficult to measure an appropriate summary and because 2) different facts matter in different domains. Since the quality of a summary is difficult to quantify, human intervention in the modelling process is necessary, which makes text summarisation more resource intensive than other NLP tasks. The importance of text summarising for the police domain is that it could enable cases to be reviewed more rapidly and easily. 

This section introduced three methods beyond classification that could be leveraged to support the analysis of free text data. The next section moves beyond models and explores that data types that can be analysed.  


\subsection{Data}

\subsubsection{Document types} Police forces use many text documents that are not MO descriptions and incident logs. Police forces generate a large volume of text data when they conduct their operations. These data include case summaries, witness reports, communication logs, and arrest reports. The underlying characteristics of these documents vary and, potentially, so do the techniques that are applicable to them. As mentioned previously, longer documents are difficult to analyse with PTMs because of the additional memory that is required to track the entire document. Shorter documents, such as communication logs, may contain large numbers of abbreviations or irregular grammar, especially if they have been recorded hastily or if they are verbatim reports. These different document types therefore entail different challenges that must be overcome in different ways. Researching PTMs with the different document types would be conducive to a more extensive understanding of the effectiveness of PTMs in the police domain.

\subsubsection{Languages}The studies that were presented here concern texts in English, but similar models exist for other languages e.g. \parencite{scao2022bloom}. Translation models make it possible to translate non-English text into English in order to use English-language models. Further research on the use of non-English models to prove that similar tasks are conceivable in languages other than English would also be useful in proving that the approaches that were explored here can be used widely.


\subsubsection{Bias} The results from the bias investigations that were presented here are encouraging, but they only reflect one part of the journey from data creation to model output. In particular, the studies that were presented here focus on algorithmic bias. To the best of the author’s knowledge, little is known about the biases that affect the comprehensiveness of textual crime records. This section of the data journey merits additional research.

\subsection{Explainability} Although explainability was introduced and explored in the thesis, the visualisations that were provided were not tested formally for effectiveness. Explainability, as outlined in Chapter 6, is specific to audiences. Accordingly, visualisations and methods should be tested with all intended audiences. This testing should include members of the public (e.g., victims who have suffered crimes that may be classified), the police officers who use the outputs, and the individuals who authorise the use of the models.

\subsection{Summary} In summary, there are many potential avenues for research, particularly those that have been shown to work in other domains. However, two general problems may restrict the use of NLP with police data. Firstly, long texts are problematic because computational requirements increase quadratically with text length – very long texts require considerably more computational power and memory than what is generally feasible. Secondly, around 1,000 labelled texts were required for each problem in this thesis. In some instances, resource demands may be disproportionate to the gravity of the problem that has to be solved. These challenges, however, are being tackled actively, and it is likely that the restrictions that were outlined will become less stringent in the future. Consequently, NLP techniques will become applicable to a wide variety of police data and police requirements for interrogating free-text data.


\section{Concluding Remarks} This thesis set out to determine whether modern NLP methods, namely PTMs, can be employed effectively within the POP methodology. The author hoped that the analytical burden of the POP process would be reduced. The analytical requirements were previously thought to obstruct the successful completion of POP projects. The use of PTM was explored by exploring intra-incident variation experimentally in relation to descriptions of burglary and ASB. In each case, intra-incident variation was specified by using PTMs to arrive at classifications on the basis of a predetermined characteristic. The robustness of the results was explored by reference to model transparency and bias. The results for burglary were also replicated with data from different police forces.

The results of the experiments were then analysed in the context of the POP cycle, and they were found to be particularly useful in the initial (scanning) and the latter (Assesment) phases of the POP cycle. PTMs can reduce the analytical burdens of that cycle. Issues of implementation were also discussed, and areas for future work were explored. In conclusion, police forces can benefit considerably from the use of NLP techniques and models. PTMs, in particular, are highly useful for extracting information from free-text material. This information can then be used for a variety of purposes, including the formulation of crime prevention strategies.






