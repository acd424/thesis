\chapter{Introduction}

\section{Motivation}
This research is located at the intersection of a well-established crime reduction methodology, problem-oriented policing (POP), and a growing field in artificial intelligence, natural language processing (NLP), which is increasingly making it easier to draw information from unstructured data.

POP is a method of policing first introduced in 1979 by Herman Goldstein \parencite{gold79} . POP replaces the traditional policing model, which focusses on responding to single incidents as they occur. By contrast, POP seeks to prevent problems ( problems are defined below but are essentially any issue the police are expected to deal with) from reoccurring by analysing how they occurred in the first place and then intervening in the generation process. In this regard, an essential element for conducting POP is understanding the conditions that allowed the problem to occur. Crimes are a subset of the problems that police forces face, albeit a large and important one. POPâ€™s focus is on problems, not just crimes. However, the POP terminology sometimes focusses on crimes only. Where the terminology does so, this is normally without loss of generality of the effect of POP on all problems encountered by the police.

POP seeks to tackle problems, which it defines as a \say{A cluster of similar incidents, whether crimes or acts of disorder, that the police are expected to handle} \parencite{popchap11}. Of immediate interest from this definition is that problems should have similar incidents, which is related not just to the outcomes but also to the processes and external factors that occur leading up to, during and after the incident.  As an example if a problem burglaries in an area, then an incident would be the individual burglaries. Most of the analytical effort required in POP is expended in scanning for and then grouping similar crimes, followed by fully analysing incidents to identify similar factors, processes or mechanisms influencing the incident occurrence. This research focuses on these two analytical processes.

This intersection between POP and NLP is important. Although POP works \parencite{hinkle2020problem}, it is necessary, yet seemingly difficult, to follow the POP framework correctly. Thus, although POP has shown benefits, it has not realised its full potential \parencite{POPUCL}. The impediment to POP that this body of research aims to reduce is the analytical burden necessary to understand the specificity of the problem or problems at hand. POP works best by attacking the mechanisms of the problems so that the opportunities to commit the crime (or other non-criminal activity) are significantly reduced \parencite{clarke2003becoming}.This is achieved by understanding the causes and mechanism of the problems and then finding ameliorating strategies. Understanding problems so that they can be attacked and grouping problems so that solutions can be used efficiently are key components of POP. However, studies have shown that the analytical power and data required to do this efficiently are difficult for police forces to muster and coordinate \parencite{sidebottom2020implementing}. This research will show how NLP models can efficiently extract the required information to conduct POP interventions. 

Although police forces have a mandate to record all crime \parencite{home2020crime}, the bulk of the recorded information about crime is contained in textual data, such as in police generated crime notes, witness statements or forensic reports. Accessing this information is largely completed manually \parencite{goldstein1990},, and as such, it is often a long and laborious task. Given the resource pressures, the work must be completed selectively \parencite{rogerson2016utility}. Unlocking access to this information would enable analysts and officers practicable access to a much wider source of information with which to do their job. An important sub-set of this textual data is the modus operandi (MO) notes that must accompany every recorded crime. Two sources of text data are introduced next as potential sources of information.

MO data are relatively short sections of text of around three to eleven sentences that describe what is initially known about the crime. The text is generally limited to the knowledge that can be gathered by the initial responding officers from their provisional review of the crime scene and any victim or witness statements. Further investigations, for instance by detectives or forensics, are held in the case reports and are not detailed in the MO data. As such, they offer a concise but limited view of the crime. Alongside the MO data, more typical crime data is recorded in a structured way, with fields such as time, date, location, crime classification and victim characteristics often included. These more structured statistics have been exploited to a greater extent than the unstructured MO data. \textcite{mapchap10, ratcliffe1998aoristic, braga2014effects, weisel2016analyzing} for a selection of methods.

A second source used in this thesis is police incident logs. These are usually generated by a call operator who responds to emergency and nonemergency calls from the public. Typically, they record the details of an incident as it is in progress. More recently, incident logs have also started to encompass reports from the public that have been logged electronically, through email or online forms. Police incident logs differ from MO data in two important respects. First, they are not generally edited, and they provide multiple perspectives over time rather than a single post-hoc view. Second, they cover both crime and non-crime incidents, so they have a much broader reach than MO data. The two data types are discussed more extensively in Chapter 8.

Recent advances in NLP, where the basis of models has moved from a more logical and rules-based approach to a more probabilistic approach, have allowed more powerful models to be applied to free-text problems \parencite{kumar2011natural}. Improvements in processing power and the availability of data have also pushed the boundaries of the state-of-the-art (SOTA) models. The improvements in NLP have led to the development of suites of generic open-source tools \parencite{manning2014stanford, benoit2018quanteda, loper2002nltk}. These toolkits are designed so that they can be reused on different sets of natural language texts to solve similar problems, such as classification or question and answering, without the need to build models from scratch each time a problem is encountered.

Pre-trained language models (PTMs) are an import class of these generic NLP tools. A useful analogy for understanding PTMs is a university student embarking on their first graduate job (PTM) compared to someone without education (generic ML model). The training to be successful at the job will have two parts. First, the trainee receives broad formal education,  culminating in a university degree. They have a lot of knowledge and understand broad concepts, but it has taken many years and lots of effort to get them to that point. When they reach their new job, they will need additional, job- specific training tailored to the problems they need to solve for that role. The graduate needs additional domain knowledge, which will build on the broad concepts that they already understand. However, this additional knowledge is quicker to impart because of their already broad understanding of the underlying concepts. In the case of humans the cost of the education is somewhat dependant on the amount of people to be educated, however humans have a significant drawback that computers models do not have - they cant easily be replicated. As PTMs can be easily replicated (you can download a copy of one from the internet in minutes) that upfront training cost is only bourne once.

Using a PTM is like employing a graduate for the first time. The model already has some understanding, or knowledge, of the problem. In this case, the problem is what English words mean. However, the model does not understand the specific problem well. Therefore, the model must be given some on the job training before it is released for work. Previously, one could not \say{employ a graduate}, one had to do all the model training oneself. Now, with the introduction of PTMs, one can skip most of the training and start with a model that already has a broad understanding of the problem. This means that significant complexity and effort in using NLP models has been removed from the end user.

This research focuses on investigating the use of these PTMs with police free text data. While the PTMs have been found to work well in other domains, they have yet to be tested on free text generated by the police on problems that are important to the police. Can these PTMs be leveraged by the police and therefore taken advantage of for their lower barriers to use? That is the fundamental question of this thesis.


\section{Research Questions}

The research question and its supporting objectives are stated here with a brief explanation to guide the reader through the next few sections. The research questions are examined more thoroughly in relation to the literature outlined in the rest of the document in Chapter 7. The main research question is as follows:

s

In this thesis extracting information will focus on automatically classifying texts to understand if an event did or did not happen. For example Burglary MO texts will be classified to understand if the burglar used force to enter a property or not.

The research supporting objectives are:

\begin{enumerate}
\item {\bf Identify the extent of NLP usage with police data.} This is largely conducted in the literature survey, which is the focus of Chapter 6.

\item {\bf Evaluate how effective PTMs are with MO data.} PTMs are formally introduced and explained in Chapter 5. MO data is introduced in Chapter 8. Study 1 investigates the use of PTMs to classify MO text data.

\item {\bf Evaluate how effective PTMs are with Police Incident data.} As mentioned above, police incident data is another source of information on problems the police face. Using PTMs to classify police incident logs is investigated in Study 2.

\item {\bf Evaluate how effective Active Learning is with police data.}  Active learning is a method to reduce the amount of data that PTMs need to learn. It has been found to work with other data types, but its effectiveness with police data is unknown. Active learning is introduced in Chapter 4 and studied in study 1.

\item {\bf Identify which parts of the POP process might be best supported by the use of PTMs.} The POP process is explained fully in Chapter 3. It is likely that different parts of the process will find differing uses and utility for PTMs. Lessons for POP are drawn from both studies and outlined in Part 3.

\item {\bf Identify implementation barriers for PTMs.} Any new process is likely to have implementation barriers, which are important to identify so that they can be minimised. Discussed in Part 3.
\end{enumerate}



\section{Thesis Structure} This thesis has three parts. Part 1 focusses on the introduction and background to the research. Part 2 reviews studies exploring the use of NLP with police free text data. Part 3 draws on the research of Part 2 and explores the implications for POP.

Part 1 begins with an introduction, which sets out the main ideas of the research. The next chapters then explain the theoretical underpinnings of POP, namely routine activity theory and situational crime theory. POP is then discussed in more detail, identifying key problems with widespread usage. After POP is explained, the focus switches to the more technical aspects of the research. First, machine learning (ML) is introduced. Next, ML with free-text data, namely NLP, is explored including the theory and use behind PTMs. The penultimate chapter draws these POP and NLP together by conducting a literature survey of the use of NLP with police generated free-text data.

Part 2 focuses on the two main study areas, which are delineated by the type of police free text data used. Both studies focus on the utility of PTMs with police generated free text. Study 1 uses MO data. Study 2 uses police incident log data. Study 1 is split into three parts. The first part, study 1a, investigates the classification of MO texts in one police force area (known as PF1). Study 1b investigates the efficiency of active learning, using the data and models from study 1a. Study 1c replicates and extends study 1a using data from a separate police force (PF2). Study 2 only has one part and is focussed on classifying police incident logs in a single police force (PF2). There is a table at the end of Chapter 7 (\ref{tab:study} that captures this detail.

The final section of the thesis, Part 3, summarises the lessons and implications from the studies in Part 2 in light of the conclusions from Part 1. It does so in two chapters. The first chapter discusses the implication of NLP usage for POP, particularly how and where PTMs might be used to alleviate the analytical burden. The second chapter takes a broader look at potential future research directions of PTMs with police free text data.




